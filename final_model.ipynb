{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/Users/Shanti/Desktop/Job Search/Personal Projects/features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shanti/Desktop/Job Search/Personal Projects/audio_env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_class=11,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0], &#x27;gamma&#x27;: [0, 0.1],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1], &#x27;max_depth&#x27;: [4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_class=11,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0], &#x27;gamma&#x27;: [0, 0.1],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1], &#x27;max_depth&#x27;: [4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_class=11,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8, 1.0], 'gamma': [0, 0.1],\n",
       "                         'learning_rate': [0.01, 0.1], 'max_depth': [4, 6],\n",
       "                         'n_estimators': [100, 200], 'subsample': [0.8, 1.0]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [4, 6],\n",
    "    'gamma': [0, 0.1,],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# Create the model\n",
    "xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit grid search on resampled training data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.7516778523489933\n",
      "Best Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cel       0.69      0.74      0.72        73\n",
      "         cla       0.73      0.69      0.71       105\n",
      "         flu       0.69      0.66      0.67        87\n",
      "         gac       0.74      0.90      0.81       108\n",
      "         gel       0.67      0.81      0.73       140\n",
      "         org       0.75      0.80      0.77       139\n",
      "         pia       0.82      0.74      0.78       162\n",
      "         sax       0.70      0.59      0.64       127\n",
      "         tru       0.83      0.79      0.81       116\n",
      "         vio       0.75      0.63      0.68       126\n",
      "         voi       0.85      0.87      0.86       158\n",
      "\n",
      "    accuracy                           0.75      1341\n",
      "   macro avg       0.75      0.75      0.74      1341\n",
      "weighted avg       0.75      0.75      0.75      1341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print('Best Model Classification Report:')\n",
    "print(classification_report(y_test, y_pred_best, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_names.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "# After training your model, save it using joblib.dump.\n",
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'best_xgboost_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "joblib.dump(feature_names, 'feature_names.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "# When you need to use the model again, load it using joblib.load.\n",
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "best_model = joblib.load('best_xgboost_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_all_mp3_to_wav(root_directory):\n",
    "    for subdir, _, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp3'):\n",
    "                mp3_path = os.path.join(subdir, file)\n",
    "                wav_path = os.path.join(subdir, file.replace('.mp3', '.wav'))\n",
    "                audio = AudioSegment.from_mp3(mp3_path)\n",
    "                audio.export(wav_path, format='wav')\n",
    "                print(f\"Converted {mp3_path} to {wav_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted /Users/Shanti/Desktop/Job Search/Personal Projects/IRMAS-TrainingData/jazz/03TakeFive.mp3 to /Users/Shanti/Desktop/Job Search/Personal Projects/IRMAS-TrainingData/jazz/03TakeFive.wav\n"
     ]
    }
   ],
   "source": [
    "# Define the root directory where your MP3 files are stored\n",
    "root_directory = '/Users/Shanti/Desktop/Job Search/Personal Projects/IRMAS-TrainingData/jazz'\n",
    "\n",
    "# Run the conversion\n",
    "convert_all_mp3_to_wav(root_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import essentia.standard\n",
    "from essentia.streaming import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_EXT = \"*.wav\"\n",
    "\n",
    "class FeatureExtractor(essentia.streaming.CompositeBase):\n",
    "\n",
    "    def __init__(self, frameSize=2048, hopSize=1024, sampleRate=44100.):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "        halfSampleRate = sampleRate / 2\n",
    "        minFrequency = sampleRate / frameSize\n",
    "\n",
    "        fc = FrameCutter(frameSize=frameSize, hopSize=hopSize)\n",
    "        zcr = ZeroCrossingRate()\n",
    "        fc.frame >> zcr.signal\n",
    "        w = Windowing(type='blackmanharris62')\n",
    "        fc.frame >> w.frame\n",
    "        spec = Spectrum()\n",
    "        w.frame >> spec.frame\n",
    "        energy = Energy()\n",
    "        spec.spectrum >> energy.array\n",
    "        rms = RMS()\n",
    "        spec.spectrum >> rms.array\n",
    "        square1 = UnaryOperator(type='square')\n",
    "        centroid = Centroid(range=halfSampleRate)\n",
    "        spec.spectrum >> square1.array >> centroid.array\n",
    "        cm = CentralMoments(range=halfSampleRate)\n",
    "        ds = DistributionShape()\n",
    "        spec.spectrum >> cm.array\n",
    "        cm.centralMoments >> ds.centralMoments\n",
    "        mfcc = MFCC(numberBands=40, numberCoefficients=13, sampleRate=sampleRate)\n",
    "        spec.spectrum >> mfcc.spectrum\n",
    "        mfcc.bands >> None\n",
    "        lpc = LPC(order=10, sampleRate=sampleRate)\n",
    "        spec.spectrum >> lpc.frame\n",
    "        lpc.reflection >> None\n",
    "        square2 = UnaryOperator(type='square')\n",
    "        decrease = Decrease(range=halfSampleRate)\n",
    "        spec.spectrum >> square2.array >> decrease.array\n",
    "        ebr_low = EnergyBand(startCutoffFrequency=20, stopCutoffFrequency=150, sampleRate=sampleRate)\n",
    "        ebr_mid_low = EnergyBand(startCutoffFrequency=150, stopCutoffFrequency=800, sampleRate=sampleRate)\n",
    "        ebr_mid_hi = EnergyBand(startCutoffFrequency=800, stopCutoffFrequency=4000, sampleRate=sampleRate)\n",
    "        ebr_hi = EnergyBand(startCutoffFrequency=4000, stopCutoffFrequency=20000, sampleRate=sampleRate)\n",
    "        spec.spectrum >> ebr_low.spectrum\n",
    "        spec.spectrum >> ebr_mid_low.spectrum\n",
    "        spec.spectrum >> ebr_mid_hi.spectrum\n",
    "        spec.spectrum >> ebr_hi.spectrum\n",
    "        hfc = HFC(sampleRate=sampleRate)\n",
    "        spec.spectrum >> hfc.spectrum\n",
    "        flux = Flux()\n",
    "        spec.spectrum >> flux.spectrum\n",
    "        ro = RollOff(sampleRate=sampleRate)\n",
    "        spec.spectrum >> ro.spectrum\n",
    "        sp = StrongPeak()\n",
    "        spec.spectrum >> sp.spectrum\n",
    "        barkBands = BarkBands(numberBands=27, sampleRate=sampleRate)\n",
    "        spec.spectrum >> barkBands.spectrum\n",
    "        crest = Crest()\n",
    "        barkBands.bands >> crest.array\n",
    "        flatness = FlatnessDB()\n",
    "        barkBands.bands >> flatness.array\n",
    "        cmbb = CentralMoments(range=26)\n",
    "        dsbb = DistributionShape()\n",
    "        barkBands.bands >> cmbb.array\n",
    "        cmbb.centralMoments >> dsbb.centralMoments\n",
    "        scx = SpectralComplexity(magnitudeThreshold=0.005, sampleRate=sampleRate)\n",
    "        spec.spectrum >> scx.spectrum\n",
    "        pitch = PitchYinFFT(frameSize=frameSize, sampleRate=sampleRate)\n",
    "        spec.spectrum >> pitch.spectrum\n",
    "        pitch.pitch >> None\n",
    "        ps = PitchSalience(sampleRate=sampleRate)\n",
    "        spec.spectrum >> ps.spectrum\n",
    "        sc = SpectralContrast(frameSize=frameSize, sampleRate=sampleRate, numberBands=6, lowFrequencyBound=20, highFrequencyBound=11000, neighbourRatio=0.4, staticDistribution=0.15)\n",
    "        spec.spectrum >> sc.spectrum\n",
    "        peaks = SpectralPeaks(orderBy='frequency', minFrequency=minFrequency, sampleRate=sampleRate)\n",
    "        spec.spectrum >> peaks.spectrum\n",
    "        diss = Dissonance()\n",
    "        peaks.frequencies >> diss.frequencies\n",
    "        peaks.magnitudes >> diss.magnitudes\n",
    "        harmPeaks = HarmonicPeaks()\n",
    "        peaks.frequencies >> harmPeaks.frequencies\n",
    "        peaks.magnitudes >> harmPeaks.magnitudes\n",
    "        pitch.pitch >> harmPeaks.pitch\n",
    "        tristimulus = Tristimulus()\n",
    "        harmPeaks.harmonicFrequencies >> tristimulus.frequencies\n",
    "        harmPeaks.harmonicMagnitudes >> tristimulus.magnitudes\n",
    "        odd2even = OddToEvenHarmonicEnergyRatio()\n",
    "        harmPeaks.harmonicFrequencies >> odd2even.frequencies\n",
    "        harmPeaks.harmonicMagnitudes >> odd2even.magnitudes\n",
    "        inharmonicity = Inharmonicity()\n",
    "        harmPeaks.harmonicFrequencies >> inharmonicity.frequencies\n",
    "        harmPeaks.harmonicMagnitudes >> inharmonicity.magnitudes\n",
    "\n",
    "        self.inputs['signal'] = fc.signal\n",
    "        self.outputs['zcr'] = zcr.zeroCrossingRate\n",
    "        self.outputs['spectral_energy'] = energy.energy\n",
    "        self.outputs['spectral_rms'] = rms.rms\n",
    "        self.outputs['mfcc'] = mfcc.mfcc\n",
    "        self.outputs['lpc'] = lpc.lpc\n",
    "        self.outputs['spectral_centroid'] = centroid.centroid\n",
    "        self.outputs['spectral_kurtosis'] = ds.kurtosis\n",
    "        self.outputs['spectral_spread'] = ds.spread\n",
    "        self.outputs['spectral_skewness'] = ds.skewness\n",
    "        self.outputs['spectral_dissonance'] = diss.dissonance\n",
    "        self.outputs['sccoeffs'] = sc.spectralContrast\n",
    "        self.outputs['scvalleys'] = sc.spectralValley\n",
    "        self.outputs['spectral_decrease'] = decrease.decrease\n",
    "        self.outputs['spectral_energyband_low'] = ebr_low.energyBand\n",
    "        self.outputs['spectral_energyband_middle_low'] = ebr_mid_low.energyBand\n",
    "        self.outputs['spectral_energyband_middle_high'] = ebr_mid_hi.energyBand\n",
    "        self.outputs['spectral_energyband_high'] = ebr_hi.energyBand\n",
    "        self.outputs['hfc'] = hfc.hfc\n",
    "        self.outputs['spectral_flux'] = flux.flux\n",
    "        self.outputs['spectral_rolloff'] = ro.rollOff\n",
    "        self.outputs['spectral_strongpeak'] = sp.strongPeak\n",
    "        self.outputs['barkbands'] = barkBands.bands\n",
    "        self.outputs['spectral_crest'] = crest.crest\n",
    "        self.outputs['spectral_flatness_db'] = flatness.flatnessDB\n",
    "        self.outputs['barkbands_kurtosis'] = dsbb.kurtosis\n",
    "        self.outputs['barkbands_spread'] = dsbb.spread\n",
    "        self.outputs['barkbands_skewness'] = dsbb.skewness\n",
    "        self.outputs['spectral_complexity'] = scx.spectralComplexity\n",
    "        self.outputs['pitch_instantaneous_confidence'] = pitch.pitchConfidence\n",
    "        self.outputs['pitch_salience'] = ps.pitchSalience\n",
    "        self.outputs['inharmonicity'] = inharmonicity.inharmonicity\n",
    "        self.outputs['oddtoevenharmonicenergyratio'] = odd2even.oddToEvenHarmonicEnergyRatio\n",
    "        self.outputs['tristimulus'] = tristimulus.tristimulus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia.standard\n",
    "from essentia.streaming import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to preprocess a new song\n",
    "def preprocess_song(file_path):\n",
    "    loader = essentia.streaming.EqloudLoader(filename=file_path)\n",
    "    fEx = FeatureExtractor(frameSize=2048, hopSize=1024, sampleRate=loader.paramValue('sampleRate'))\n",
    "    p = essentia.Pool()\n",
    "\n",
    "    loader.audio >> fEx.signal\n",
    "\n",
    "    for desc, output in fEx.outputs.items():\n",
    "        output >> (p, desc)\n",
    "\n",
    "    essentia.run(loader)\n",
    "\n",
    "    stats = ['mean', 'var', 'dmean', 'dvar']\n",
    "    statsPool = essentia.standard.PoolAggregator(defaultStats=stats)(p)\n",
    "    \n",
    "    pool_dict = dict()\n",
    "    for desc in statsPool.descriptorNames():\n",
    "        if type(statsPool[desc]) is float:\n",
    "            pool_dict[desc] = statsPool[desc]\n",
    "        elif type(statsPool[desc]) is np.ndarray:\n",
    "            for i, value in enumerate(statsPool[desc]):\n",
    "                feature_name = \"{desc_name}{desc_number}.{desc_stat}\".format(\n",
    "                    desc_name=desc.split('.')[0],\n",
    "                    desc_number=i,\n",
    "                    desc_stat=desc.split('.')[1])\n",
    "                pool_dict[feature_name] = value\n",
    "    \n",
    "    features = pd.DataFrame(pool_dict, index=[os.path.basename(file_path)])\n",
    "    features = scaler.transform(features)\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the model, scaler, and label encoder\n",
    "best_model = joblib.load('best_xgboost_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "feature_names = joblib.load('feature_names.pkl')\n",
    "\n",
    "# Function to predict instruments in a song\n",
    "def predict_instruments(model, file_path, scaler, label_encoder,feature_names):\n",
    "    # Preprocess the song to extract features\n",
    "    features = preprocess_song(file_path)\n",
    "\n",
    "    # Ensure features are a DataFrame\n",
    "    if not isinstance(features, pd.DataFrame):\n",
    "        features = pd.DataFrame(features, columns=feature_names)\n",
    "        \n",
    "    # Ensure features have the same columns as those used during training\n",
    "    features = features.reindex(columns=feature_names, fill_value=0)\n",
    "    \n",
    "    # Standardize the features\n",
    "    features = scaler.transform(features)\n",
    "    \n",
    "    # Predict the probabilities of each class\n",
    "    probabilities = model.predict_proba(features)[0]\n",
    "\n",
    "    # Get the class labels\n",
    "    classes = label_encoder.classes_\n",
    "    \n",
    "    # Create a sorted list of (class, probability) tuples\n",
    "    sorted_probabilities = sorted(zip(classes, probabilities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted instruments (from highest to lowest probability):\n",
      "pia: 0.1986\n",
      "org: 0.1773\n",
      "sax: 0.1458\n",
      "cel: 0.0927\n",
      "vio: 0.0836\n",
      "tru: 0.0760\n",
      "gel: 0.0731\n",
      "gac: 0.0468\n",
      "cla: 0.0461\n",
      "voi: 0.0317\n",
      "flu: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING  ] clipping oddtoevenharmonicenergyratio to maximum allowed value\n",
      "[ WARNING  ] clipping oddtoevenharmonicenergyratio to maximum allowed value\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = '/Users/Shanti/Desktop/Job Search/Personal Projects/IRMAS-TrainingData/jazz/03TakeFive.wav'  # Update with the actual path to your song file\n",
    "predicted_instruments = predict_instruments(best_model, file_path, scaler, label_encoder,feature_names)\n",
    "\n",
    "print(f'Predicted instruments (from highest to lowest probability):')\n",
    "for instrument, probability in predicted_instruments:\n",
    "    print(f'{instrument}: {probability:.4f}')\n",
    "\n",
    "# This approach will allow you to see all the instruments present in the song, \n",
    "# ranked by their probability, providing a more detailed and informative prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T his one gets only the piano\n",
    "# import joblib\n",
    "\n",
    "# # Load the model, scaler, and label encoder\n",
    "# best_model = joblib.load('best_xgboost_model.pkl')\n",
    "# scaler = joblib.load('scaler.pkl')\n",
    "# label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# # Function to predict instruments in a song\n",
    "# def predict_instruments(model, file_path, scaler, label_encoder):\n",
    "#     # Preprocess the song to extract features\n",
    "#     features = preprocess_song(file_path)\n",
    "    \n",
    "#     # Standardize the features\n",
    "#     features = scaler.transform(features)\n",
    "    \n",
    "#     # Predict the class label\n",
    "#     prediction = model.predict(features)\n",
    "    \n",
    "#     # Decode the class label\n",
    "#     instrument = label_encoder.inverse_transform(prediction)\n",
    "#     return instrument\n",
    "\n",
    "# # Example usage\n",
    "# file_path = '/Users/Shanti/Desktop/Job Search/Personal Projects/IRMAS-TrainingData/jazz/03TakeFive.wav'  # Update with the actual path to your song file\n",
    "# predicted_instruments = predict_instruments(best_model, file_path, scaler, label_encoder)\n",
    "\n",
    "# print(f'Predicted instruments: {predicted_instruments}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.35.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in ./audio_env/lib/python3.8/site-packages (from streamlit) (1.24.4)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in ./audio_env/lib/python3.8/site-packages (from streamlit) (24.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in ./audio_env/lib/python3.8/site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in ./audio_env/lib/python3.8/site-packages (from streamlit) (10.3.0)\n",
      "Collecting protobuf<5,>=3.20 (from streamlit)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-16.1.0-cp38-cp38-macosx_10_15_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./audio_env/lib/python3.8/site-packages (from streamlit) (2.32.3)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./audio_env/lib/python3.8/site-packages (from streamlit) (4.12.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./audio_env/lib/python3.8/site-packages (from streamlit) (6.4)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./audio_env/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./audio_env/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./audio_env/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./audio_env/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./audio_env/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./audio_env/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./audio_env/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./audio_env/lib/python3.8/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
      "  Using cached MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in ./audio_env/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (6.4.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pkgutil-resolve-name>=1.3.10 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl.metadata (624 bytes)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached rpds_py-0.18.1-cp38-cp38-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./audio_env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./audio_env/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair<6,>=4.0->streamlit) (3.19.0)\n",
      "Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading pyarrow-16.1.0-cp38-cp38-macosx_10_15_x86_64.whl (28.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.3/28.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_x86_64.whl (14 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.18.1-cp38-cp38-macosx_10_12_x86_64.whl (327 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: toolz, toml, tenacity, smmap, rpds-py, pyarrow, protobuf, pkgutil-resolve-name, mdurl, MarkupSafe, click, cachetools, blinker, attrs, referencing, markdown-it-py, jinja2, gitdb, rich, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed MarkupSafe-2.1.5 altair-5.3.0 attrs-23.2.0 blinker-1.8.2 cachetools-5.3.3 click-8.1.7 gitdb-4.0.11 gitpython-3.1.43 jinja2-3.1.4 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 markdown-it-py-3.0.0 mdurl-0.1.2 pkgutil-resolve-name-1.3.10 protobuf-4.25.3 pyarrow-16.1.0 pydeck-0.9.1 referencing-0.35.1 rich-13.7.1 rpds-py-0.18.1 smmap-5.0.1 streamlit-1.35.0 tenacity-8.3.0 toml-0.10.2 toolz-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
